{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ RLAIF Code Generation on SageMaker\n",
        "\n",
        "Train a code generation model using Reinforcement Learning from AI Feedback!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install sagemaker boto3 transformers trl datasets accelerate torch --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sagemaker\n",
        "from sagemaker.pytorch import PyTorch\n",
        "import boto3\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize SageMaker session\n",
        "sagemaker_session = sagemaker.Session()\n",
        "role = sagemaker.get_execution_role()\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "\n",
        "print(f\"Role: {role}\")\n",
        "print(f\"Bucket: {bucket}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Quick Local Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the reward model locally\n",
        "from reward_model import AIRewardModel\n",
        "\n",
        "print(\"Testing AI Reward Model...\")\n",
        "reward_model = AIRewardModel(\"Salesforce/codet5-small\")\n",
        "\n",
        "# Test on good code\n",
        "good_code = \"\"\"def add_numbers(a, b):\n",
        "    return a + b\"\"\"\n",
        "\n",
        "reward = reward_model.evaluate_code_solution(\n",
        "    \"Write a function to add two numbers\",\n",
        "    good_code,\n",
        "    \"add_numbers(3, 5)\",\n",
        "    \"8\"\n",
        ")\n",
        "print(f\"Good code reward: {reward:.3f}\")\n",
        "\n",
        "# Test on bad code\n",
        "bad_code = \"print('hello')\"\n",
        "bad_reward = reward_model.evaluate_code_solution(\n",
        "    \"Write a function to add two numbers\",\n",
        "    bad_code,\n",
        "    \"add_numbers(3, 5)\",\n",
        "    \"8\"\n",
        ")\n",
        "print(f\"Bad code reward: {bad_reward:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Launch SageMaker Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "MODEL_NAME = \"Salesforce/codegen-350M-mono\"  # Start small!\n",
        "INSTANCE_TYPE = \"ml.g4dn.xlarge\"  # GPU instance\n",
        "EPISODES = 20\n",
        "\n",
        "# Create unique job name\n",
        "job_name = f\"rlaif-code-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "output_path = f\"s3://{bucket}/rlaif-training/{job_name}\"\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Instance: {INSTANCE_TYPE}\")\n",
        "print(f\"Episodes: {EPISODES}\")\n",
        "print(f\"Output: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create PyTorch estimator\n",
        "estimator = PyTorch(\n",
        "    entry_point=\"train_sagemaker.py\",\n",
        "    source_dir=\".\",  # Directory with your Python files\n",
        "    role=role,\n",
        "    instance_type=INSTANCE_TYPE,\n",
        "    instance_count=1,\n",
        "    framework_version=\"2.0\",\n",
        "    py_version=\"py310\",\n",
        "    hyperparameters={\n",
        "        \"model_name\": MODEL_NAME,\n",
        "        \"episodes\": EPISODES,\n",
        "        \"use_lora\": True\n",
        "    },\n",
        "    output_path=output_path,\n",
        "    base_job_name=\"rlaif-code\",\n",
        "    environment={\n",
        "        \"PYTORCH_CUDA_ALLOC_CONF\": \"max_split_size_mb:512\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Estimator created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training (this will take 20-30 minutes for 350M model)\n",
        "print(\"ðŸš€ Starting training job...\")\n",
        "estimator.fit(wait=False)\n",
        "\n",
        "print(f\"\\nâœ… Training job submitted!\")\n",
        "print(f\"Job name: {estimator.latest_training_job.name}\")\n",
        "print(f\"\\nMonitor progress in SageMaker console or run next cell\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Monitor Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stream training logs (run this to see progress)\n",
        "estimator.logs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model location (after training completes)\n",
        "model_data = estimator.model_data\n",
        "print(f\"Model location: {model_data}\")\n",
        "\n",
        "# Download model\n",
        "!aws s3 cp {model_data} ./trained_model.tar.gz\n",
        "!tar -xzf trained_model.tar.gz\n",
        "print(\"Model downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and test the trained model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load model\n",
        "model_path = \"./\"  # Path where model was extracted\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Test generation\n",
        "def generate_code(prompt):\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.7,\n",
        "            do_sample=True\n",
        "        )\n",
        "    return tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"Write a Python function that adds two numbers.\",\n",
        "    \"Write a Python function that checks if a number is even.\",\n",
        "    \"Write a Python function that reverses a string.\"\n",
        "]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    code = generate_code(prompt)\n",
        "    print(f\"Generated:\\n{code}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Expected Results\n",
        "\n",
        "After 20-30 episodes with `codegen-350M-mono`:\n",
        "\n",
        "**Before Training:**\n",
        "- Random text or incomplete code\n",
        "- Average reward: ~0.2-0.3\n",
        "\n",
        "**After Training:**\n",
        "- Valid Python functions\n",
        "- Correct implementations for simple problems\n",
        "- Average reward: ~0.7-0.9\n",
        "\n",
        "## ðŸ’° Cost Estimate\n",
        "\n",
        "- **ml.g4dn.xlarge**: $0.736/hour\n",
        "- **20 episodes**: ~30 minutes\n",
        "- **Total cost**: ~$0.40\n",
        "\n",
        "## ðŸš€ Next Steps\n",
        "\n",
        "1. Try more episodes (50-100) for better results\n",
        "2. Use larger models (CodeLlama-7B) with bigger instances\n",
        "3. Expand the dataset with more complex problems\n",
        "4. Fine-tune the reward model for specific code styles"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}